{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SmartFit AI: Intelligent Fitness & Nutrition Analysis"
      ],
      "metadata": {
        "id": "c285VLoVhOcL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wNQRDYUTfqX4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Final_data.csv\")"
      ],
      "metadata": {
        "id": "IylPsblEgO8C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "01_data_cleaning_and_feature_engineering.py\n",
        "\n",
        "Purpose:\n",
        " - Clean dataset already loaded as df\n",
        " - Handle missing values, outliers, encoding, and feature engineering\n",
        " - Return cleaned dataframe ready for EDA or modeling\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Cleaning and preprocessing\n",
        "# -----------------------------\n",
        "\n",
        "def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Make column names lowercase and underscore separated.\"\"\"\n",
        "    df = df.copy()\n",
        "    df.columns = [\n",
        "        c.strip().lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"%\", \"pct\")\n",
        "        for c in df.columns\n",
        "    ]\n",
        "    return df\n",
        "\n",
        "\n",
        "def basic_type_casting(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Try to convert columns to numeric or datetime (only if column looks like a date).\"\"\"\n",
        "    df = df.copy()\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == object:\n",
        "            # Try numeric first\n",
        "            try:\n",
        "                df[col] = pd.to_numeric(df[col].str.replace(\",\", \"\"), errors=\"raise\")\n",
        "                continue\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            # Only try datetime if column name hints it's a date or time\n",
        "            if any(k in col for k in [\"date\", \"time\", \"year\", \"month\"]):\n",
        "                try:\n",
        "                    df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n",
        "                except Exception:\n",
        "                    pass\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def handle_missing_values(df: pd.DataFrame, strategy_num=\"median\", strategy_cat=\"most_frequent\") -> pd.DataFrame:\n",
        "    \"\"\"Fill missing numeric and categorical values.\"\"\"\n",
        "    df = df.copy()\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "\n",
        "    if len(num_cols):\n",
        "        df[num_cols] = SimpleImputer(strategy=strategy_num).fit_transform(df[num_cols])\n",
        "    if len(cat_cols):\n",
        "        df[cat_cols] = SimpleImputer(strategy=strategy_cat).fit_transform(df[cat_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def cap_outliers_iqr(df: pd.DataFrame, factor=1.5) -> pd.DataFrame:\n",
        "    \"\"\"Cap outliers using IQR.\"\"\"\n",
        "    df = df.copy()\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    for col in num_cols:\n",
        "        q1, q3 = df[col].quantile([0.25, 0.75])\n",
        "        iqr = q3 - q1\n",
        "        lower, upper = q1 - factor * iqr, q3 + factor * iqr\n",
        "        df[col] = df[col].clip(lower, upper)\n",
        "    return df\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Feature engineering\n",
        "# -----------------------------\n",
        "\n",
        "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Add derived features.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # calorie balance\n",
        "    if \"calories\" in df.columns and \"calories_burned\" in df.columns:\n",
        "        df[\"calorie_balance\"] = df[\"calories\"] - df[\"calories_burned\"]\n",
        "\n",
        "    # workout efficiency\n",
        "    if \"calories_burned\" in df.columns and \"session_duration_hours\" in df.columns:\n",
        "        df[\"workout_efficiency\"] = df[\"calories_burned\"] / df[\"session_duration_hours\"].replace({0: np.nan})\n",
        "        df[\"workout_efficiency\"] = df[\"workout_efficiency\"].fillna(0)\n",
        "\n",
        "    # macro percentages\n",
        "    if all(c in df.columns for c in [\"carbs\", \"proteins\", \"fats\"]):\n",
        "        total = df[[\"carbs\", \"proteins\", \"fats\"]].sum(axis=1).replace(0, np.nan)\n",
        "        df[\"pct_carbs\"] = df[\"carbs\"] / total\n",
        "        df[\"pct_proteins\"] = df[\"proteins\"] / total\n",
        "        df[\"pct_fats\"] = df[\"fats\"] / total\n",
        "        df[[\"pct_carbs\", \"pct_proteins\", \"pct_fats\"]] = df[[\"pct_carbs\", \"pct_proteins\", \"pct_fats\"]].fillna(0)\n",
        "\n",
        "    # protein per kg\n",
        "    if \"proteins\" in df.columns and \"weight_kg\" in df.columns:\n",
        "        df[\"protein_per_kg\"] = df[\"proteins\"] / df[\"weight_kg\"].replace({0: np.nan})\n",
        "        df[\"protein_per_kg\"] = df[\"protein_per_kg\"].fillna(0)\n",
        "\n",
        "    # bmi\n",
        "    if \"bmi\" not in df.columns and all(c in df.columns for c in [\"weight_kg\", \"height_m\"]):\n",
        "        df[\"bmi\"] = df[\"weight_kg\"] / (df[\"height_m\"] ** 2)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Master cleaning pipeline\n",
        "# -----------------------------\n",
        "\n",
        "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Apply all cleaning + feature engineering steps.\"\"\"\n",
        "    df = clean_column_names(df)\n",
        "    df = basic_type_casting(df)\n",
        "    df = handle_missing_values(df)\n",
        "    df = cap_outliers_iqr(df)\n",
        "    df = feature_engineering(df)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "AgRaPs0Ngbvn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df is already loaded\n",
        "df_cleaned = preprocess_data(df)\n"
      ],
      "metadata": {
        "id": "g44B4N4zhwZe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.to_csv(\"cleaned_file.csv\", index = False)"
      ],
      "metadata": {
        "id": "aS-OsWFCiSja"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OglBBOlDjD52"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}